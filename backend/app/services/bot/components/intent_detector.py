"""
IntentDetector - Detecta inten√ß√£o com fallback autom√°tico entre regras e ML
Responsabilidade √∫nica: determinar a inten√ß√£o do usu√°rio
"""

from typing import Tuple, Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class IntentDetector:
    """Detector de inten√ß√£o h√≠brido (regras + ML)"""
    
    def __init__(self, intent_engine, classifier, config: Optional[Dict[str, Any]] = None):
        """
        Args:
            intent_engine: Motor de regras (IntentEngine)
            classifier: Classificador ML (BotClassifier)
            config: Configura√ß√µes opcionais (thresholds, etc)
        """
        self.engine = intent_engine
        self.classifier = classifier
        self.config = config or {}
        
        # Thresholds configur√°veis
        self.rule_confidence_threshold = self.config.get("rule_confidence_threshold", 0.8)
        self.ml_min_confidence = self.config.get("ml_min_confidence", 0.6)
        self.ml_improvement_margin = self.config.get("ml_improvement_margin", 0.15)
        self.min_words_for_ml = self.config.get("min_words_for_ml", 3)
    
    async def detect(self, text: str, context: Optional[Dict] = None) -> Tuple[str, float, str]:
        """
        Detectar inten√ß√£o com fallback autom√°tico
        
        Args:
            text: Texto do usu√°rio
            context: Contexto adicional (hist√≥rico, estado, etc)
            
        Returns:
            Tuple[intent, confidence, source] - inten√ß√£o, confian√ßa (0-1), fonte ('rule' ou 'ml')
        """
        if not text:
            return "unknown", 0.0, "none"
        
        context = context or {}
        
        # 1. REGRA (r√°pido e determin√≠stico)
        rule_intent, rule_entities, rule_conf = self.engine.detect(text)
        logger.debug(f"üîç REGRA: {rule_intent} ({rule_conf:.2%}) - '{text}'")
        
        # 2. DECIDIR SE USA ML
        use_ml = self._should_use_ml(text, rule_conf, context)
        
        if not use_ml:
            logger.debug(f"‚è≠Ô∏è PULANDO ML (regra confiante ou texto curto)")
            return rule_intent, rule_conf, "rule"
        
        # 3. TENTAR ML
        ml_intent, ml_conf = self.classifier.classify(text)
        logger.debug(f"ü§ñ ML: {ml_intent} ({ml_conf:.2%})")
        
        # 4. DECIDIR QUAL USAR
        final_intent, final_conf, source = self._choose_best(
            rule_intent, rule_conf,
            ml_intent, ml_conf,
            context
        )
        
        logger.info(f"‚úÖ INTENT FINAL: {final_intent} ({final_conf:.2%}) via {source.upper()}")
        
        return final_intent, final_conf, source
    
    def _should_use_ml(self, text: str, rule_conf: float, context: Dict) -> bool:
        """Decidir se deve usar ML baseado em heur√≠sticas"""
        
        # ML n√£o dispon√≠vel
        if not self.classifier.ready:
            return False
        
        word_count = len(text.split())
        
        # Sempre usar ML para frases longas ou regra incerta
        should_use = (
            rule_conf < self.rule_confidence_threshold or  # Regra incerta
            word_count > self.min_words_for_ml or  # Frase longa
            rule_conf < 0.6  # Regra com baixa confian√ßa
        )
        
        return should_use
    
    def _choose_best(
        self, 
        rule_intent: str, 
        rule_conf: float,
        ml_intent: str, 
        ml_conf: float,
        context: Dict
    ) -> Tuple[str, float, str]:
        """
        Escolher melhor predi√ß√£o entre regra e ML
        
        Estrat√©gia:
        - ML vence se: confian√ßa > threshold E (confian√ßa > regra OU regra muito incerta)
        - Regra vence nos demais casos (mais conservador)
        """
        
        # ML precisa ter confian√ßa m√≠nima
        if ml_conf < self.ml_min_confidence:
            logger.debug(f"‚ùå ML confian√ßa baixa ({ml_conf:.2%} < {self.ml_min_confidence:.2%})")
            return rule_intent, rule_conf, "rule"
        
        # ML vence se significativamente melhor que regra
        if ml_conf > rule_conf + self.ml_improvement_margin:
            logger.debug(f"‚úÖ ML vence (margem: {ml_conf - rule_conf:.2%})")
            return ml_intent, ml_conf, "ml"
        
        # ML vence se regra muito incerta
        if ml_conf > rule_conf and rule_conf < 0.5:
            logger.debug(f"‚úÖ ML vence (regra incerta: {rule_conf:.2%})")
            return ml_intent, ml_conf, "ml"
        
        # Padr√£o: manter regra (mais conservador)
        logger.debug(f"‚ùå MANTENDO REGRA (conf: {rule_conf:.2%})")
        return rule_intent, rule_conf, "rule"


class ContextAwareIntentDetector(IntentDetector):
    """
    Detector de inten√ß√£o que usa hist√≥rico da conversa para desambiguar
    """
    
    def __init__(self, intent_engine, classifier, config: Optional[Dict[str, Any]] = None):
        super().__init__(intent_engine, classifier, config)
    
    async def detect(self, text: str, context: Optional[Dict] = None) -> Tuple[str, float, str]:
        """Detectar inten√ß√£o considerando contexto anterior"""
        
        # Detec√ß√£o base
        base_intent, base_conf, source = await super().detect(text, context)
        
        # Se confian√ßa alta, retornar direto
        if base_conf > 0.8:
            return base_intent, base_conf, source
        
        # Tentar melhorar com contexto
        if context and "history" in context and len(context["history"]) > 0:
            enhanced_intent, enhanced_conf = self._enhance_with_context(
                text, base_intent, base_conf, context
            )
            
            if enhanced_conf > base_conf:
                logger.info(f"üìà Contexto melhorou confian√ßa: {base_conf:.2%} ‚Üí {enhanced_conf:.2%}")
                return enhanced_intent, enhanced_conf, "context"
        
        return base_intent, base_conf, source
    
    def _enhance_with_context(
        self, 
        text: str, 
        base_intent: str, 
        base_conf: float, 
        context: Dict
    ) -> Tuple[str, float]:
        """Melhorar detec√ß√£o usando hist√≥rico"""
        
        history = context.get("history", [])
        if not history:
            return base_intent, base_conf
        
        last_turn = history[-1]
        last_intent = last_turn.get("intent")
        current_state = context.get("state", "idle")
        
        # Regras contextuais
        word_count = len(text.split())
        
        # Se √∫ltima inten√ß√£o foi "services" e resposta curta, provavelmente √© sele√ß√£o
        if last_intent == "services" and word_count <= 3:
            logger.debug(f"üîÑ Contexto: √∫ltima intent=services, resposta curta ‚Üí select_service")
            return "select_service", 0.75
        
        # Se foi perguntando data e tem n√∫mero, √© confirma√ß√£o de data
        if current_state == "asking_date" and any(char.isdigit() for char in text):
            logger.debug(f"üîÑ Contexto: estado=asking_date, tem n√∫mero ‚Üí confirm_date")
            return "confirm_date", 0.8
        
        # Se foi perguntando hor√°rio e tem padr√£o de hora
        if current_state in ("asking_time", "asking_window"):
            import re
            if re.search(r'\d{1,2}h|\d{1,2}:\d{2}|manh√£|tarde|noite', text.lower()):
                logger.debug(f"üîÑ Contexto: estado={current_state}, tem hora ‚Üí confirm_time")
                return "confirm_time", 0.8
        
        # Padr√£o: retornar base
        return base_intent, base_conf

